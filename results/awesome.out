speechbrain.utils.quirks - Applied quirks (see `speechbrain.utils.quirks`): [allow_tf32, disable_jit_profiling]
speechbrain.utils.quirks - Excluded quirks specified by the `SB_DISABLE_QUIRKS` environment (comma-separated list): []
speechbrain.core - Beginning experiment!
speechbrain.core - Experiment folder: results/conformer_small/7775
librispeech_prepare - Skipping preparation, completed in previous run.
speechbrain.utils.fetching - Fetch lm.ckpt: Fetching from HuggingFace Hub 'speechbrain/asr-transformer-transformerlm-librispeech' if not cached
speechbrain.utils.fetching - Fetch tokenizer.ckpt: Fetching from HuggingFace Hub 'speechbrain/asr-transformer-transformerlm-librispeech' if not cached
speechbrain.utils.parameter_transfer - Loading pretrained files for: lm, tokenizer
speechbrain.core - Info: precision arg from hparam file is used
speechbrain.core - Info: max_grad_norm arg from hparam file is used
speechbrain.core - Info: grad_accumulation_factor arg from hparam file is used
speechbrain.core - Gradscaler enabled: False. Using precision: fp32.
speechbrain.core - ASR Model Statistics:
* Total Number of Trainable Parameters: 13.3M
* Total Number of Parameters: 13.3M
* Trainable Parameters represent 100.0000% of the total size.
speechbrain.utils.checkpoints - Would load a checkpoint here, but none found yet.
speechbrain.utils.epoch_loop - Going into epoch 1
speechbrain.utils.train_logger - epoch: 1, lr: 9.37e-04, steps: 23437, optimizer: Adam - train loss: 2.47e+02 - valid loss: 1.48e+02, valid ACC: 2.13e-01
speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/conformer_small/7775/save/CKPT+2025-04-01+10-46-05+00
speechbrain.utils.epoch_loop - Going into epoch 2
speechbrain.utils.train_logger - epoch: 2, lr: 7.30e-04, steps: 46874, optimizer: Adam - train loss: 2.22e+02 - valid loss: 1.43e+02, valid ACC: 2.46e-01
speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/conformer_small/7775/save/CKPT+2025-04-01+12-32-43+00
speechbrain.utils.epoch_loop - Going into epoch 3
speechbrain.utils.train_logger - epoch: 3, lr: 5.96e-04, steps: 70311, optimizer: Adam - train loss: 2.18e+02 - valid loss: 1.45e+02, valid ACC: 2.56e-01
speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/conformer_small/7775/save/CKPT+2025-04-01+14-20-04+00
speechbrain.utils.epoch_loop - Going into epoch 4
speechbrain.utils.train_logger - epoch: 4, lr: 5.16e-04, steps: 93748, optimizer: Adam - train loss: 2.16e+02 - valid loss: 1.45e+02, valid ACC: 2.53e-01
speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/conformer_small/7775/save/CKPT+2025-04-01+16-08-02+00
speechbrain.utils.epoch_loop - Going into epoch 5
speechbrain.utils.train_logger - epoch: 5, lr: 4.62e-04, steps: 117185, optimizer: Adam - train loss: 2.15e+02 - valid loss: 1.38e+02, valid ACC: 2.63e-01
speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/conformer_small/7775/save/CKPT+2025-04-01+17-54-50+00
speechbrain.utils.epoch_loop - Going into epoch 6
speechbrain.utils.train_logger - epoch: 6, lr: 4.22e-04, steps: 140622, optimizer: Adam - train loss: 2.14e+02 - valid loss: 1.38e+02, valid ACC: 2.63e-01
speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/conformer_small/7775/save/CKPT+2025-04-01+19-41-41+00
speechbrain.utils.epoch_loop - Going into epoch 7
speechbrain.utils.train_logger - epoch: 7, lr: 3.90e-04, steps: 164059, optimizer: Adam - train loss: 2.13e+02 - valid loss: 1.41e+02, valid ACC: 2.64e-01
speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/conformer_small/7775/save/CKPT+2025-04-01+21-29-48+00
speechbrain.utils.epoch_loop - Going into epoch 8
speechbrain.utils.train_logger - epoch: 8, lr: 3.65e-04, steps: 187496, optimizer: Adam - train loss: 2.13e+02 - valid loss: 1.42e+02, valid ACC: 2.69e-01
speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/conformer_small/7775/save/CKPT+2025-04-01+23-17-19+00
speechbrain.utils.epoch_loop - Going into epoch 9
speechbrain.utils.train_logger - epoch: 9, lr: 3.44e-04, steps: 210933, optimizer: Adam - train loss: 2.13e+02 - valid loss: 1.52e+02, valid ACC: 2.71e-01
speechbrain.utils.checkpoints - Saved an end-of-epoch checkpoint in results/conformer_small/7775/save/CKPT+2025-04-02+01-03-10+00
speechbrain.utils.epoch_loop - Going into epoch 10
